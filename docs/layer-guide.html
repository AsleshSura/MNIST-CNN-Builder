<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CNN Layer Guide - MNIST CNN Builder</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
            line-height: 1.6;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
        }

        .header {
            text-align: center;
            padding: 40px 0;
            color: white;
        }

        .header h1 {
            font-size: 3rem;
            font-weight: 700;
            margin-bottom: 15px;
            text-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        .header p {
            font-size: 1.2rem;
            font-weight: 300;
            opacity: 0.9;
            max-width: 600px;
            margin: 0 auto;
        }

        .nav-bar {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 15px 20px;
            margin-bottom: 30px;
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
            justify-content: center;
        }

        .nav-link {
            color: white;
            text-decoration: none;
            padding: 8px 16px;
            border-radius: 8px;
            transition: all 0.3s ease;
            font-weight: 500;
        }

        .nav-link:hover {
            background: rgba(255, 255, 255, 0.2);
            transform: translateY(-2px);
        }

        .nav-link.active {
            background: rgba(255, 255, 255, 0.3);
        }

        .content {
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            margin-bottom: 30px;
        }

        .section {
            margin-bottom: 50px;
        }

        .section h2 {
            color: #4F46E5;
            font-size: 2rem;
            font-weight: 600;
            margin-bottom: 25px;
            padding-bottom: 10px;
            border-bottom: 3px solid #E0E7FF;
        }

        .layer-card {
            background: #F8FAFC;
            border: 2px solid #E2E8F0;
            border-radius: 15px;
            padding: 25px;
            margin-bottom: 30px;
            transition: all 0.3s ease;
        }

        .layer-card:hover {
            border-color: #4F46E5;
            box-shadow: 0 10px 25px rgba(79, 70, 229, 0.1);
            transform: translateY(-2px);
        }

        .layer-card h3 {
            color: #1E293B;
            font-size: 1.4rem;
            font-weight: 600;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .layer-icon {
            width: 30px;
            height: 30px;
            border-radius: 8px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            color: white;
            font-size: 14px;
        }

        .conv-icon { background: #10B981; }
        .activation-icon { background: #F59E0B; }
        .regularization-icon { background: #EF4444; }
        .structural-icon { background: #8B5CF6; }

        .layer-subtitle {
            color: #64748B;
            font-style: italic;
            margin-bottom: 15px;
        }

        .how-it-works {
            background: #FEF3C7;
            border-left: 4px solid #F59E0B;
            padding: 15px 20px;
            margin: 20px 0;
            border-radius: 0 8px 8px 0;
        }

        .how-it-works h4 {
            color: #92400E;
            font-weight: 600;
            margin-bottom: 10px;
        }

        .parameters {
            background: #DBEAFE;
            border-left: 4px solid #3B82F6;
            padding: 15px 20px;
            margin: 20px 0;
            border-radius: 0 8px 8px 0;
        }

        .parameters h4 {
            color: #1E40AF;
            font-weight: 600;
            margin-bottom: 10px;
        }

        .best-practices {
            background: #D1FAE5;
            border-left: 4px solid #10B981;
            padding: 15px 20px;
            margin: 20px 0;
            border-radius: 0 8px 8px 0;
        }

        .best-practices h4 {
            color: #065F46;
            font-weight: 600;
            margin-bottom: 10px;
        }

        ul {
            margin-left: 20px;
            margin-top: 10px;
        }

        li {
            margin-bottom: 8px;
        }

        .formula {
            background: #F1F5F9;
            border: 1px solid #CBD5E1;
            border-radius: 8px;
            padding: 15px;
            font-family: 'Courier New', monospace;
            text-align: center;
            margin: 15px 0;
            font-weight: 500;
        }

        .back-button {
            position: fixed;
            top: 20px;
            left: 20px;
            background: rgba(255, 255, 255, 0.2);
            backdrop-filter: blur(10px);
            color: white;
            text-decoration: none;
            padding: 12px 20px;
            border-radius: 10px;
            font-weight: 500;
            transition: all 0.3s ease;
        }

        .back-button:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
        }

        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }

            .header h1 {
                font-size: 2rem;
            }

            .content {
                padding: 20px;
            }

            .nav-bar {
                flex-direction: column;
                text-align: center;
            }

            .back-button {
                position: static;
                margin-bottom: 20px;
                display: inline-block;
            }
        }
    </style>
</head>
<body>
    <a href="/MNIST-CNN-Builder/index.html" class="back-button">‚Üê Back to Main</a>

    <div class="container">
        <div class="header">
            <h1>üß± CNN Layer Guide</h1>
            <p>Understanding the building blocks of Convolutional Neural Networks</p>
        </div>

        <div class="nav-bar">
            <a href="#convolutional" class="nav-link">Convolutional</a>
            <a href="#activation" class="nav-link">Activation</a>
            <a href="#regularization" class="nav-link">Regularization</a>
            <a href="#structural" class="nav-link">Structural</a>
        </div>

        <div class="content">
            <section id="convolutional" class="section">
                <h2>üîç Convolutional Layers</h2>
                
                <div class="layer-card">
                    <h3><span class="layer-icon conv-icon">C2D</span>Conv2D (Convolutional Layer)</h3>
                    <p class="layer-subtitle">The foundation of any CNN, Conv2D layers perform feature extraction through convolution operations.</p>
                    
                    <div class="how-it-works">
                        <h4>How it works:</h4>
                        <ul>
                            <li>Applies learnable filters (kernels) across the input image</li>
                            <li>Each filter detects specific patterns (edges, textures, shapes)</li>
                            <li>Preserves spatial relationships between pixels</li>
                            <li>Shares parameters across the entire input, reducing overfitting</li>
                        </ul>
                    </div>

                    <div class="parameters">
                        <h4>Parameters:</h4>
                        <ul>
                            <li><strong>Filters</strong>: Number of feature detectors (8, 16, 32, 64, 128, 256, 512)</li>
                            <li><strong>Kernel Size</strong>: Size of the convolution window (3x3, 5x5, 7x7)</li>
                            <li><strong>Strides</strong>: Step size for filter movement (1, 2)</li>
                            <li><strong>Padding</strong>: Border handling ('valid' or 'same')</li>
                            <li><strong>Activation</strong>: Built-in activation function (optional)</li>
                        </ul>
                    </div>

                    <div class="best-practices">
                        <h4>Best Practices:</h4>
                        <ul>
                            <li>Start with fewer filters (8-16) in early layers</li>
                            <li>Increase filter count in deeper layers for complex pattern recognition</li>
                            <li>Use 3x3 kernels for most applications (proven most effective)</li>
                            <li>Apply padding='same' to preserve spatial dimensions</li>
                        </ul>
                    </div>
                </div>

                <div class="layer-card">
                    <h3><span class="layer-icon conv-icon">MP2</span>MaxPooling2D (Pooling Layer)</h3>
                    <p class="layer-subtitle">Reduces spatial dimensions while retaining the most important features.</p>
                    
                    <div class="how-it-works">
                        <h4>How it works:</h4>
                        <ul>
                            <li>Divides input into non-overlapping regions</li>
                            <li>Selects the maximum value from each region</li>
                            <li>Reduces computational complexity and overfitting</li>
                            <li>Provides translation invariance (small position changes don't affect output)</li>
                        </ul>
                    </div>

                    <div class="parameters">
                        <h4>Parameters:</h4>
                        <ul>
                            <li><strong>Pool Size</strong>: Dimensions of pooling window (2x2, 3x3)</li>
                            <li><strong>Strides</strong>: Step size for pooling operation</li>
                            <li><strong>Padding</strong>: Border handling strategy</li>
                        </ul>
                    </div>

                    <div class="best-practices">
                        <h4>Benefits:</h4>
                        <ul>
                            <li>Reduces memory usage and computation time</li>
                            <li>Makes features more robust to small translations</li>
                            <li>Helps prevent overfitting by reducing parameter count</li>
                            <li>Increases receptive field of subsequent layers</li>
                        </ul>
                    </div>
                </div>
            </section>

            <section id="activation" class="section">
                <h2>‚ö° Activation Layers</h2>
                
                <div class="layer-card">
                    <h3><span class="layer-icon activation-icon">ReLU</span>ReLU (Rectified Linear Unit)</h3>
                    <p class="layer-subtitle">The most popular activation function in modern deep learning.</p>
                    
                    <div class="how-it-works">
                        <h4>How it works:</h4>
                        <ul>
                            <li>Outputs the input if positive, zero otherwise: f(x) = max(0, x)</li>
                            <li>Introduces non-linearity essential for learning complex patterns</li>
                            <li>Solves the vanishing gradient problem better than sigmoid/tanh</li>
                            <li>Computationally efficient (simple thresholding operation)</li>
                        </ul>
                    </div>

                    <div class="best-practices">
                        <h4>Advantages:</h4>
                        <ul>
                            <li>Fast computation and gradient calculation</li>
                            <li>Sparse activation (many neurons output zero)</li>
                            <li>No saturation for positive values</li>
                            <li>Biological plausibility (similar to neuron activation)</li>
                        </ul>
                    </div>

                    <div class="parameters">
                        <h4>When to use:</h4>
                        <ul>
                            <li>After every Conv2D layer</li>
                            <li>In hidden Dense layers</li>
                            <li>Default choice for most CNN architectures</li>
                        </ul>
                    </div>
                </div>

                <div class="layer-card">
                    <h3><span class="layer-icon activation-icon">SM</span>Softmax</h3>
                    <p class="layer-subtitle">Converts raw prediction scores into probability distributions.</p>
                    
                    <div class="how-it-works">
                        <h4>How it works:</h4>
                        <ul>
                            <li>Exponentiates each input and normalizes by the sum</li>
                            <li>Ensures outputs sum to 1.0 (valid probability distribution)</li>
                            <li>Emphasizes the largest values while suppressing smaller ones</li>
                            <li>Essential for multi-class classification problems</li>
                        </ul>
                    </div>

                    <div class="formula">
                        softmax(x_i) = exp(x_i) / Œ£(exp(x_j)) for all j
                    </div>

                    <div class="parameters">
                        <h4>Usage:</h4>
                        <ul>
                            <li>Always the final layer for classification tasks</li>
                            <li>Only use with Dense layers</li>
                            <li>Perfect for MNIST's 10-class digit classification</li>
                        </ul>
                    </div>
                </div>
            </section>

            <section id="regularization" class="section">
                <h2>üõ°Ô∏è Regularization Layers</h2>
                
                <div class="layer-card">
                    <h3><span class="layer-icon regularization-icon">DO</span>Dropout</h3>
                    <p class="layer-subtitle">Prevents overfitting by randomly setting neurons to zero during training.</p>
                    
                    <div class="how-it-works">
                        <h4>How it works:</h4>
                        <ul>
                            <li>Randomly "drops out" (sets to zero) a percentage of neurons</li>
                            <li>Forces the network to not rely on specific neurons</li>
                            <li>Creates ensemble effect with multiple sub-networks</li>
                            <li>Only active during training, disabled during inference</li>
                        </ul>
                    </div>

                    <div class="parameters">
                        <h4>Parameters:</h4>
                        <ul>
                            <li><strong>Rate</strong>: Fraction of neurons to drop (0.1 to 0.5 typical)</li>
                        </ul>
                    </div>

                    <div class="best-practices">
                        <h4>Best Practices:</h4>
                        <ul>
                            <li>Use 0.25-0.5 for Dense layers</li>
                            <li>Place before final classification layer</li>
                            <li>Higher rates for larger networks</li>
                            <li>Don't use in convolutional layers for small networks</li>
                        </ul>
                    </div>
                </div>

                <div class="layer-card">
                    <h3><span class="layer-icon regularization-icon">BN</span>BatchNormalization</h3>
                    <p class="layer-subtitle">Normalizes layer inputs to improve training stability and speed.</p>
                    
                    <div class="how-it-works">
                        <h4>How it works:</h4>
                        <ul>
                            <li>Normalizes each batch to have zero mean and unit variance</li>
                            <li>Adds learnable scale and shift parameters</li>
                            <li>Reduces internal covariate shift</li>
                            <li>Acts as implicit regularization</li>
                        </ul>
                    </div>

                    <div class="best-practices">
                        <h4>Benefits:</h4>
                        <ul>
                            <li>Faster training convergence</li>
                            <li>Higher learning rates possible</li>
                            <li>Less sensitive to weight initialization</li>
                            <li>Reduces need for other regularization techniques</li>
                        </ul>
                    </div>

                    <div class="parameters">
                        <h4>Placement:</h4>
                        <ul>
                            <li>Typically after Conv2D layers, before activation</li>
                            <li>Can be used after Dense layers</li>
                            <li>Experiment with placement for best results</li>
                        </ul>
                    </div>
                </div>
            </section>

            <section id="structural" class="section">
                <h2>üèóÔ∏è Structural Layers</h2>
                
                <div class="layer-card">
                    <h3><span class="layer-icon structural-icon">FL</span>Flatten</h3>
                    <p class="layer-subtitle">Converts multi-dimensional feature maps to 1D vectors for Dense layers.</p>
                    
                    <div class="how-it-works">
                        <h4>How it works:</h4>
                        <ul>
                            <li>Reshapes 3D tensor (height √ó width √ó channels) to 1D</li>
                            <li>Preserves all information, just changes organization</li>
                            <li>Required transition between convolutional and dense layers</li>
                            <li>No learnable parameters</li>
                        </ul>
                    </div>

                    <div class="parameters">
                        <h4>Usage:</h4>
                        <ul>
                            <li>Place exactly once between Conv2D and Dense layers</li>
                            <li>Essential bridge in CNN architecture</li>
                            <li>Typically after final pooling layer</li>
                        </ul>
                    </div>
                </div>

                <div class="layer-card">
                    <h3><span class="layer-icon structural-icon">D</span>Dense (Fully Connected)</h3>
                    <p class="layer-subtitle">Traditional neural network layer where each neuron connects to all previous neurons.</p>
                    
                    <div class="how-it-works">
                        <h4>How it works:</h4>
                        <ul>
                            <li>Computes weighted sum of all inputs plus bias</li>
                            <li>Applies activation function to the result</li>
                            <li>Learns global patterns across the entire flattened feature map</li>
                            <li>High parameter count but powerful pattern recognition</li>
                        </ul>
                    </div>

                    <div class="parameters">
                        <h4>Parameters:</h4>
                        <ul>
                            <li><strong>Units</strong>: Number of neurons in the layer</li>
                            <li><strong>Activation</strong>: Activation function to apply</li>
                        </ul>
                    </div>

                    <div class="best-practices">
                        <h4>Architecture Guidelines:</h4>
                        <ul>
                            <li>Start with 64-128 units for hidden layers</li>
                            <li>Final layer must have 10 units for MNIST (one per digit)</li>
                            <li>Can stack multiple Dense layers</li>
                            <li>Consider Dropout between Dense layers</li>
                        </ul>
                    </div>
                </div>
            </section>
        </div>
    </div>

    <script>
        // Smooth scrolling for navigation links
        document.querySelectorAll('.nav-link').forEach(link => {
            link.addEventListener('click', function(e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                target.scrollIntoView({
                    behavior: 'smooth',
                    block: 'start'
                });
                
                // Update active navigation
                document.querySelectorAll('.nav-link').forEach(l => l.classList.remove('active'));
                this.classList.add('active');
            });
        });

        // Update active navigation on scroll
        window.addEventListener('scroll', () => {
            const sections = document.querySelectorAll('.section');
            const navLinks = document.querySelectorAll('.nav-link');
            
            let current = '';
            sections.forEach(section => {
                const sectionTop = section.offsetTop - 100;
                if (pageYOffset >= sectionTop) {
                    current = section.getAttribute('id');
                }
            });

            navLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === '#' + current) {
                    link.classList.add('active');
                }
            });
        });
    </script>
</body>
</html>
